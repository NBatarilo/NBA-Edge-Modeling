{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "71dbaa1c-5eab-4319-9bb6-be4a737e6b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nba_api.stats.endpoints import leaguegamelog\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time\n",
    "import xgboost as xgb\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "969e6a39-7676-4ea4-9b5d-a5c1a38b5415",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed488c7d-59d6-485a-aacd-d664e1b08132",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_advanced_stats(year):\n",
    "    data = json.load(open(f\"{year}.json\"))\n",
    "    advanced_stats = pd.DataFrame(data['resultSets'][0]['rowSet'], columns = data['resultSets'][0]['headers'])    \n",
    "    return advanced_stats    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a073fba3-76e4-4b96-a4d2-ba591a8ffb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Can use this to get means and standard deviations\n",
    "def generate_game_stats(df, teams, year): \n",
    "    #all_stats_arr = np.empty((30, 77, 19))\n",
    "    all_teams_stats_df = pd.DataFrame()\n",
    "    for i, team in enumerate(teams):\n",
    "        temp_df = df[df['TEAM_NAME'] == team]\n",
    "        advanced_stats = get_advanced_stats(year)\n",
    "        #Merge with temp \n",
    "        temp_df = temp_df.merge(advanced_stats, on = [\"GAME_ID\", \"TEAM_ID\"], suffixes = (\"\", \"_y\"))\n",
    "        to_drop = [x for x in temp_df if x.endswith('_y')]\n",
    "        temp_df.drop(to_drop, axis=1, inplace=True)\n",
    "        \n",
    "        temp_df = temp_df.sort_values(by = ['GAME_DATE'])\n",
    "        temp_df = temp_df.set_index('GAME_ID')\n",
    "        key_data = temp_df[['GAME_DATE', 'TEAM_NAME', 'MATCHUP', 'WL']].iloc[7:]\n",
    "        temp_df = temp_df[[\n",
    "           'FGM', 'FGA', 'FG_PCT', 'FG3M',\n",
    "           'FG3A', 'FG3_PCT', 'FTM', 'FTA', 'FT_PCT', 'OREB', 'DREB', 'REB', 'AST',\n",
    "           'STL', 'BLK', 'TOV', 'PF', 'PTS', 'PLUS_MINUS', 'E_OFF_RATING', 'OFF_RATING', 'E_DEF_RATING',\n",
    "           'DEF_RATING', 'E_NET_RATING', 'NET_RATING', 'AST_PCT', 'AST_TO',\n",
    "           'AST_RATIO', 'OREB_PCT', 'DREB_PCT', 'REB_PCT', 'TM_TOV_PCT', 'EFG_PCT',\n",
    "           'TS_PCT', 'E_PACE', 'PACE', 'PACE_PER40', 'POSS', 'PIE', 'GP_RANK',\n",
    "           'W_RANK', 'L_RANK', 'W_PCT_RANK', 'MIN_RANK', 'OFF_RATING_RANK',\n",
    "           'DEF_RATING_RANK', 'NET_RATING_RANK', 'AST_PCT_RANK', 'AST_TO_RANK',\n",
    "           'AST_RATIO_RANK', 'OREB_PCT_RANK', 'DREB_PCT_RANK', 'REB_PCT_RANK',\n",
    "           'TM_TOV_PCT_RANK', 'EFG_PCT_RANK', 'TS_PCT_RANK', 'PACE_RANK',\n",
    "           'PIE_RANK']]\n",
    "        \n",
    "        \n",
    "        \n",
    "        final_organized_stats = temp_df.rolling(7).mean().shift(periods = 1).iloc[7:]#.to_dict('index')\n",
    "        stats_with_key = pd.concat([final_organized_stats, key_data], axis = 1)\n",
    "     \n",
    "        all_teams_stats_df = pd.concat([all_teams_stats_df, stats_with_key], axis = 0)\n",
    "        \n",
    "    home_df = all_teams_stats_df[all_teams_stats_df['MATCHUP'].str.contains(\"vs.\")]\n",
    "    away_df = all_teams_stats_df[all_teams_stats_df['MATCHUP'].str.contains(\"@\")]\n",
    "    merged_game_stats_df = home_df.merge(away_df, on = \"GAME_ID\",suffixes = (\"_H\", \"_A\"))\n",
    "    merged_game_stats_df = merged_game_stats_df.sort_values(by = ['GAME_DATE_H'])\n",
    "      \n",
    "    return merged_game_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4720cefa-b177-4efc-99df-3fce22dea1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to get population mean and standard deviations - might be stupid but I think it makes sense\n",
    "#Make sure to use this on train and test set separately \n",
    "#After this, make these stats for each game their own matrices, so I could do (game_matrix - mean_matrix / std_matrix)\n",
    "def generate_population_statistics(stats_df):\n",
    "    game_means = np.empty((stats_df.shape[0], 19))\n",
    "    game_stds = np.empty((stats_df.shape[0], 19))\n",
    "    \n",
    "    for i in range(stats_df.shape[0]):\n",
    "        inter_stats_df = stats_df[stats_df['GAME_DATE_H'].str.contains(stats_df.iloc[i]['GAME_DATE_H'][0:4])]\n",
    "        inter_index = stats_df.index[i]\n",
    "        it1 = np.where(inter_stats_df.index == inter_index)[0][0]\n",
    "        team_dict = {}\n",
    "        pop_stats_arr = np.empty((30, 19))\n",
    "        it2 = it1+1\n",
    "        team_it = 0\n",
    "    \n",
    "        while len(team_dict.keys()) < 30:\n",
    "\n",
    "            if it1 >= 0:\n",
    "\n",
    "                if inter_stats_df.iloc[it1]['TEAM_NAME_H'] not in team_dict.keys():  \n",
    "                    team_dict[inter_stats_df.iloc[it1]['TEAM_NAME_H']] = ''\n",
    "\n",
    "                    pop_stats_arr[team_it] = inter_stats_df.iloc[it1][['FGM_H', 'FGA_H', 'FG_PCT_H', 'FG3M_H', 'FG3A_H', 'FG3_PCT_H', 'FTM_H',\n",
    "                   'FTA_H', 'FT_PCT_H', 'OREB_H', 'DREB_H', 'REB_H', 'AST_H', 'STL_H',\n",
    "                   'BLK_H', 'TOV_H', 'PF_H', 'PTS_H', 'PLUS_MINUS_H']].to_numpy()\n",
    "                    team_it += 1\n",
    "\n",
    "                if inter_stats_df.iloc[it1]['TEAM_NAME_A'] not in team_dict.keys():\n",
    "                    team_dict[inter_stats_df.iloc[it1]['TEAM_NAME_A']] = ''\n",
    "\n",
    "                    pop_stats_arr[team_it] = inter_stats_df.iloc[it1][['FGM_A', 'FGA_A', 'FG_PCT_A',\n",
    "                   'FG3M_A', 'FG3A_A', 'FG3_PCT_A', 'FTM_A', 'FTA_A', 'FT_PCT_A', 'OREB_A',\n",
    "                   'DREB_A', 'REB_A', 'AST_A', 'STL_A', 'BLK_A', 'TOV_A', 'PF_A', 'PTS_A',\n",
    "                   'PLUS_MINUS_A']].to_numpy()\n",
    "                    team_it += 1\n",
    "\n",
    "                it1 -= 1    \n",
    "\n",
    "            if it2 < inter_stats_df.shape[0]:\n",
    "                if inter_stats_df.iloc[it2]['TEAM_NAME_H'] not in team_dict.keys():  \n",
    "                    team_dict[inter_stats_df.iloc[it2]['TEAM_NAME_H']] = ''\n",
    "\n",
    "                    pop_stats_arr[team_it] = inter_stats_df.iloc[it2][['FGM_H', 'FGA_H', 'FG_PCT_H', 'FG3M_H', 'FG3A_H', 'FG3_PCT_H', 'FTM_H',\n",
    "                   'FTA_H', 'FT_PCT_H', 'OREB_H', 'DREB_H', 'REB_H', 'AST_H', 'STL_H',\n",
    "                   'BLK_H', 'TOV_H', 'PF_H', 'PTS_H', 'PLUS_MINUS_H']].to_numpy()\n",
    "                    team_it += 1\n",
    "\n",
    "                if inter_stats_df.iloc[it2]['TEAM_NAME_A'] not in team_dict.keys():\n",
    "                    team_dict[inter_stats_df.iloc[it2]['TEAM_NAME_A']] = ''\n",
    "\n",
    "                    pop_stats_arr[team_it] = stats_df.iloc[it2][['FGM_A', 'FGA_A', 'FG_PCT_A',\n",
    "                   'FG3M_A', 'FG3A_A', 'FG3_PCT_A', 'FTM_A', 'FTA_A', 'FT_PCT_A', 'OREB_A',\n",
    "                   'DREB_A', 'REB_A', 'AST_A', 'STL_A', 'BLK_A', 'TOV_A', 'PF_A', 'PTS_A',\n",
    "                   'PLUS_MINUS_A']].to_numpy()\n",
    "                    team_it += 1\n",
    "\n",
    "                it2 += 1\n",
    "                \n",
    "        mean_stats = np.mean(pop_stats_arr, axis = 0)        \n",
    "        std_stats = np.std(pop_stats_arr, axis = 0)\n",
    "        \n",
    "        game_means[i] = mean_stats\n",
    "        game_stds[i] = std_stats\n",
    "        \n",
    "    return game_means, game_stds    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7b22bca0-dd60-402f-be37-ef26abc1412b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to get z scores and finalize attributes as (Home minus Away)\n",
    "def normalize_and_standardize(stats_df, game_means, game_stds):\n",
    "   \n",
    "    home_stats = np.empty((stats_df.shape[0], 19))\n",
    "    away_stats = np.empty((stats_df.shape[0], 19))\n",
    "    \n",
    "    home_stats = stats_df.iloc[:, 0:19]\n",
    "    away_stats = stats_df.iloc[:, 23:42]\n",
    "    win_loss_home = stats_df.iloc[:, 22]\n",
    "    matchup = stats_df.iloc[:, [43, 20]]\n",
    "    \n",
    "    #standardize home and away stats \n",
    "    home_z = np.divide((home_stats - game_means), game_stds)\n",
    "    \n",
    "    away_z = np.divide((away_stats - game_means), game_stds)\n",
    "    \n",
    "    final = np.subtract(home_z, away_z)\n",
    "    \n",
    "    final = pd.DataFrame(final)\n",
    "\n",
    "    final = pd.concat([final, win_loss_home], axis = 1)\n",
    "    \n",
    "    return final, matchup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "bdd2734a-e5b8-4033-bf74-bcea799bc057",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_and_standardize_sklearn(stats_df):\n",
    "    \n",
    "    home_stats = np.empty((stats_df.shape[0], 51))\n",
    "    away_stats = np.empty((stats_df.shape[0], 51))\n",
    "    \n",
    "    home_stats = np.array(stats_df[['FGM_H','FGA_H','FG_PCT_H', 'FG3M_H', 'FG3A_H', 'FG3_PCT_H', 'FTM_H', 'FTA_H', 'FT_PCT_H', 'OREB_H', 'DREB_H', 'REB_H', 'AST_H', 'STL_H','BLK_H', 'TOV_H', 'PF_H', 'PTS_H', 'PLUS_MINUS_H',  'OFF_RATING_H', 'DEF_RATING_H',  'NET_RATING_H', 'AST_PCT_H', 'AST_TO_H', 'AST_RATIO_H', 'OREB_PCT_H', 'DREB_PCT_H', 'REB_PCT_H', 'TM_TOV_PCT_H','EFG_PCT_H', 'TS_PCT_H',  'PACE_H', 'PACE_PER40_H', 'POSS_H', 'PIE_H', 'GP_RANK_H', 'W_RANK_H', 'L_RANK_H', 'W_PCT_RANK_H', 'MIN_RANK_H', 'OFF_RATING_RANK_H', 'DEF_RATING_RANK_H', 'NET_RATING_RANK_H', 'AST_PCT_RANK_H', 'AST_TO_RANK_H', 'AST_RATIO_RANK_H', 'OREB_PCT_RANK_H', 'DREB_PCT_RANK_H', 'REB_PCT_RANK_H',  'TS_PCT_RANK_H',  'PIE_RANK_H']])\n",
    "    away_stats = np.array(stats_df[['FGM_A', 'FGA_A', 'FG_PCT_A', 'FG3M_A', 'FG3A_A', 'FG3_PCT_A', 'FTM_A', 'FTA_A', 'FT_PCT_A', 'OREB_A', 'DREB_A', 'REB_A', 'AST_A', 'STL_A','BLK_A', 'TOV_A', 'PF_A','PTS_A', 'PLUS_MINUS_A', 'OFF_RATING_A', 'DEF_RATING_A', 'NET_RATING_A', 'AST_PCT_A', 'AST_TO_A', 'AST_RATIO_A', 'OREB_PCT_A', 'DREB_PCT_A', 'REB_PCT_A', 'TM_TOV_PCT_A', 'EFG_PCT_A', 'TS_PCT_A',  'PACE_A', 'PACE_PER40_A', 'POSS_A', 'PIE_A', 'GP_RANK_A', 'W_RANK_A', 'L_RANK_A', 'W_PCT_RANK_A', 'MIN_RANK_A', 'OFF_RATING_RANK_A', 'DEF_RATING_RANK_A','NET_RATING_RANK_A', 'AST_PCT_RANK_A', 'AST_TO_RANK_A','AST_RATIO_RANK_A', 'OREB_PCT_RANK_A', 'DREB_PCT_RANK_A', 'REB_PCT_RANK_A', 'TS_PCT_RANK_A', 'PIE_RANK_A']])\n",
    "    win_loss_home = np.array(stats_df[['WL_H']])\n",
    "    matchup = stats_df[['TEAM_NAME_A', 'TEAM_NAME_H']]\n",
    "    \n",
    "    #standardize home and away stats \n",
    "    scaler = StandardScaler()\n",
    "    final = np.subtract(home_stats, away_stats)\n",
    "    final = scaler.fit_transform(final)\n",
    "   \n",
    "    return final, win_loss_home, matchup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "27533d1e-464d-4eae-87b1-1cdb34ebf2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Include num_years previous years plus current season games\n",
    "def generate_full_train_test(num_years):\n",
    "    start_year = 2022 - num_years\n",
    "    all_years_stats_df = pd.DataFrame()\n",
    "    #For each year, \n",
    "    for i in range(start_year, 2022):\n",
    "        time.sleep(1)\n",
    "        games = leaguegamelog.LeagueGameLog(season = str(i))\n",
    "        df = pd.DataFrame(games.get_data_frames()[0])\n",
    "        df = df[df['WL'].notnull()]\n",
    "        teams = df['TEAM_NAME'].unique()\n",
    "        stats_df = generate_game_stats(df, teams)\n",
    "        \n",
    "        all_years_stats_df = pd.concat([all_years_stats_df, stats_df], axis = 0)\n",
    "        \n",
    "    \n",
    "    #Split data into train and test and transform\n",
    "    train_stats = all_years_stats_df.iloc[:int(all_years_stats_df.shape[0]*0.7), :]\n",
    "    test_stats = all_years_stats_df.iloc[int(all_years_stats_df.shape[0]*0.7):, :]\n",
    "\n",
    "    game_means_train, game_stds_train = generate_population_statistics(train_stats)\n",
    "    game_means_test, game_stds_test = generate_population_statistics(test_stats)\n",
    "    \n",
    "    #Finalize and prepare train / test\n",
    "    final_train, matchup_train = normalize_and_standardize(train_stats, game_means_train, game_stds_train)\n",
    "    final_test, matchup_test = normalize_and_standardize(test_stats, game_means_test, game_stds_test)\n",
    "    \n",
    "    #Prepare actual train and test\n",
    "    train_X = final_train.iloc[:,:19]\n",
    "    train_Y = final_train.iloc[:,19]\n",
    "\n",
    "    test_X = final_test.iloc[:, :19]\n",
    "    test_Y = final_test.iloc[:,19]\n",
    "    \n",
    "    return train_X, train_Y, test_X, test_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e8f6539c-4a6a-47ed-988d-2ebb9c453d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_full_train_test_sklearn(num_years):\n",
    "    start_year = 2022 - num_years\n",
    "    all_years_stats_df = pd.DataFrame()\n",
    "    #For each year, \n",
    "    for i in range(start_year, 2022):\n",
    "        time.sleep(1)\n",
    "        games = leaguegamelog.LeagueGameLog(season = str(i))\n",
    "        df = pd.DataFrame(games.get_data_frames()[0])\n",
    "        df = df[df['WL'].notnull()]\n",
    "        teams = df['TEAM_NAME'].unique()\n",
    "        stats_df = generate_game_stats(df, teams, i)\n",
    "        \n",
    "        all_years_stats_df = pd.concat([all_years_stats_df, stats_df], axis = 0)\n",
    "        \n",
    "    attributes, target, matchup = normalize_and_standardize_sklearn(all_years_stats_df)\n",
    "    \n",
    "    train_X = attributes[:int(attributes.shape[0]*0.7)]\n",
    "    test_X = attributes[int(attributes.shape[0]*0.7):]\n",
    "    train_Y = target[:int(target.shape[0]*0.7)]\n",
    "    test_Y = target[int(target.shape[0]*0.7):]\n",
    "    \n",
    "    #return train_X, train_Y, test_X, test_Y\n",
    "    return train_X, train_Y, test_X, test_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f2f53df1-d326-4d88-b48b-25479a827c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_Y, test_X, test_Y = generate_full_train_test_sklearn(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ec2012a2-3cf1-4dc2-9bed-600ce2429057",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.44787057,  1.52856637, -1.77867061, ...,  1.5324116 ,\n",
       "         2.28906467,  2.07625367],\n",
       "       [-0.6590288 , -1.01020143, -0.0837882 , ...,  1.78399735,\n",
       "        -0.04268458,  0.5955098 ],\n",
       "       [-0.6590288 ,  0.12477712, -0.92308093, ..., -2.03489637,\n",
       "         0.44168846,  0.30064939],\n",
       "       ...,\n",
       "       [-0.44787057, -0.77125857,  0.1158494 , ...,  0.08897016,\n",
       "        -0.73013131, -1.08405255],\n",
       "       [-0.06778575, -0.95046571,  0.6292032 , ...,  1.64422749,\n",
       "        -1.2094979 , -0.80002614],\n",
       "       [-1.92597818, -1.48808713, -1.12679276, ...,  1.3205332 ,\n",
       "         0.1306634 ,  1.09972988]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe0b36d-3cdd-48c9-a5cd-543b2276f6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test\n",
    "games = leaguegamelog.LeagueGameLog(season = '2021')\n",
    "games_df = pd.DataFrame(games.get_data_frames()[0])\n",
    "#teams = df['TEAM_NAME'].unique()\n",
    "#stats_df = generate_game_stats(df, teams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273a73db-c3a4-41f4-b176-7ca57ce3c087",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "grid_values = {'penalty': ['l1','l2'], 'C': [0.001,0.01,0.1,1,10,100,1000], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], 'max_iter': [20, 50, 100, 200, 500, 1000]}\n",
    "clf = GridSearchCV(lr, param_grid=grid_values)\n",
    "clf.fit(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f1b78095-6610-4781-a5e2-b08fffb7ff81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\batar\\desktop\\nba\\env\\lib\\site-packages\\sklearn\\utils\\validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "#Fit model\n",
    "clf = LogisticRegression(random_state=0, C=0.01).fit(train_X, train_Y)\n",
    "y_pred = clf.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "390e906a-2d50-4bed-8de8-07a0fac99e9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6500722448443452"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train accuracy\n",
    "clf.score(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bcf6dee0-10de-4506-aabf-fe4ec689317a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6233527428746553"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test accuracy\n",
    "accuracy_score(test_Y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "635af645-bccc-490b-8262-6078709ae6e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\batar\\desktop\\nba\\env\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "c:\\users\\batar\\desktop\\nba\\env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\users\\batar\\desktop\\nba\\env\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:55:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=12,\n",
       "              num_parallel_tree=1, predictor='auto', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#XGBoost Test\n",
    "xgb_cl = xgb.XGBClassifier()\n",
    "# Fit\n",
    "xgb_cl.fit(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "28f6730f-c595-4a58-9b80-6b4616d191ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5982224946368373"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict\n",
    "y_pred = xgb_cl.predict(test_X)\n",
    "accuracy_score(test_Y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1ddaeda2-32ee-4c32-b582-9de9c6b8e7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "games = leaguegamelog.LeagueGameLog(season = '2018')\n",
    "df = pd.DataFrame(games.get_data_frames()[0])\n",
    "\n",
    "\n",
    "\n",
    "team_df = df[df['TEAM_NAME'] == 'San Antonio Spurs']\n",
    "advanced_stats = get_advanced_stats(2018)\n",
    "temp_df = team_df.merge(advanced_stats, on = [\"GAME_ID\", \"TEAM_ID\"], suffixes = (\"\", \"_y\"))\n",
    "to_drop = [x for x in temp_df if x.endswith('_y')]\n",
    "temp_df.drop(to_drop, axis=1, inplace=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
