{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71dbaa1c-5eab-4319-9bb6-be4a737e6b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\batar\\desktop\\nba\\env\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "from nba_api.stats.endpoints import leaguegamelog\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from scipy.stats import norm\n",
    "import time\n",
    "import xgboost as xgb\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "969e6a39-7676-4ea4-9b5d-a5c1a38b5415",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed488c7d-59d6-485a-aacd-d664e1b08132",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_advanced_stats(year):\n",
    "    data = json.load(open(f\"{year}.json\"))\n",
    "    advanced_stats = pd.DataFrame(data['resultSets'][0]['rowSet'], columns = data['resultSets'][0]['headers'])    \n",
    "    return advanced_stats    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a073fba3-76e4-4b96-a4d2-ba591a8ffb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Can use this to get means and standard deviations\n",
    "def generate_game_stats(df, teams, year): \n",
    "    #all_stats_arr = np.empty((30, 77, 19))\n",
    "    all_teams_stats_df = pd.DataFrame()\n",
    "    for i, team in enumerate(teams):\n",
    "        temp_df = df[df['TEAM_NAME'] == team]\n",
    "        advanced_stats = get_advanced_stats(year)\n",
    "        #Merge with temp \n",
    "        temp_df = temp_df.merge(advanced_stats, on = [\"GAME_ID\", \"TEAM_ID\"], suffixes = (\"\", \"_y\"))\n",
    "        to_drop = [x for x in temp_df if x.endswith('_y')]\n",
    "        temp_df.drop(to_drop, axis=1, inplace=True)\n",
    "        \n",
    "        temp_df = temp_df.sort_values(by = ['GAME_DATE'])\n",
    "        temp_df = temp_df.set_index('GAME_ID')\n",
    "        key_data = temp_df[['GAME_DATE', 'TEAM_NAME', 'MATCHUP', 'WL']].iloc[7:]\n",
    "        temp_df = temp_df[[\n",
    "           'FGM', 'FGA', 'FG_PCT', 'FG3M',\n",
    "           'FG3A', 'FG3_PCT', 'FTM', 'FTA', 'FT_PCT', 'OREB', 'DREB', 'REB', 'AST',\n",
    "           'STL', 'BLK', 'TOV', 'PF', 'PTS', 'PLUS_MINUS', 'E_OFF_RATING', 'OFF_RATING', 'E_DEF_RATING',\n",
    "           'DEF_RATING', 'E_NET_RATING', 'NET_RATING', 'AST_PCT', 'AST_TO',\n",
    "           'AST_RATIO', 'OREB_PCT', 'DREB_PCT', 'REB_PCT', 'TM_TOV_PCT', 'EFG_PCT',\n",
    "           'TS_PCT', 'E_PACE', 'PACE', 'PACE_PER40', 'POSS', 'PIE', 'GP_RANK',\n",
    "           'W_RANK', 'L_RANK', 'W_PCT_RANK', 'MIN_RANK', 'OFF_RATING_RANK',\n",
    "           'DEF_RATING_RANK', 'NET_RATING_RANK', 'AST_PCT_RANK', 'AST_TO_RANK',\n",
    "           'AST_RATIO_RANK', 'OREB_PCT_RANK', 'DREB_PCT_RANK', 'REB_PCT_RANK',\n",
    "           'TM_TOV_PCT_RANK', 'EFG_PCT_RANK', 'TS_PCT_RANK', 'PACE_RANK',\n",
    "           'PIE_RANK']]\n",
    "        \n",
    "        \n",
    "        \n",
    "        final_organized_stats = temp_df.rolling(7).mean().shift(periods = 1).iloc[7:]#.to_dict('index')\n",
    "        stats_with_key = pd.concat([final_organized_stats, key_data], axis = 1)\n",
    "     \n",
    "        all_teams_stats_df = pd.concat([all_teams_stats_df, stats_with_key], axis = 0)\n",
    "        \n",
    "    home_df = all_teams_stats_df[all_teams_stats_df['MATCHUP'].str.contains(\"vs.\")]\n",
    "    away_df = all_teams_stats_df[all_teams_stats_df['MATCHUP'].str.contains(\"@\")]\n",
    "    merged_game_stats_df = home_df.merge(away_df, on = \"GAME_ID\",suffixes = (\"_H\", \"_A\"))\n",
    "    merged_game_stats_df = merged_game_stats_df.sort_values(by = ['GAME_DATE_H'])\n",
    "      \n",
    "    return merged_game_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4720cefa-b177-4efc-99df-3fce22dea1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to get population mean and standard deviations - might be stupid but I think it makes sense\n",
    "#Make sure to use this on train and test set separately \n",
    "#After this, make these stats for each game their own matrices, so I could do (game_matrix - mean_matrix / std_matrix)\n",
    "def generate_population_statistics(stats_df):\n",
    "    game_means = np.empty((stats_df.shape[0], 19))\n",
    "    game_stds = np.empty((stats_df.shape[0], 19))\n",
    "    \n",
    "    for i in range(stats_df.shape[0]):\n",
    "        inter_stats_df = stats_df[stats_df['GAME_DATE_H'].str.contains(stats_df.iloc[i]['GAME_DATE_H'][0:4])]\n",
    "        inter_index = stats_df.index[i]\n",
    "        it1 = np.where(inter_stats_df.index == inter_index)[0][0]\n",
    "        team_dict = {}\n",
    "        pop_stats_arr = np.empty((30, 19))\n",
    "        it2 = it1+1\n",
    "        team_it = 0\n",
    "    \n",
    "        while len(team_dict.keys()) < 30:\n",
    "\n",
    "            if it1 >= 0:\n",
    "\n",
    "                if inter_stats_df.iloc[it1]['TEAM_NAME_H'] not in team_dict.keys():  \n",
    "                    team_dict[inter_stats_df.iloc[it1]['TEAM_NAME_H']] = ''\n",
    "\n",
    "                    pop_stats_arr[team_it] = inter_stats_df.iloc[it1][['FGM_H', 'FGA_H', 'FG_PCT_H', 'FG3M_H', 'FG3A_H', 'FG3_PCT_H', 'FTM_H',\n",
    "                   'FTA_H', 'FT_PCT_H', 'OREB_H', 'DREB_H', 'REB_H', 'AST_H', 'STL_H',\n",
    "                   'BLK_H', 'TOV_H', 'PF_H', 'PTS_H', 'PLUS_MINUS_H']].to_numpy()\n",
    "                    team_it += 1\n",
    "\n",
    "                if inter_stats_df.iloc[it1]['TEAM_NAME_A'] not in team_dict.keys():\n",
    "                    team_dict[inter_stats_df.iloc[it1]['TEAM_NAME_A']] = ''\n",
    "\n",
    "                    pop_stats_arr[team_it] = inter_stats_df.iloc[it1][['FGM_A', 'FGA_A', 'FG_PCT_A',\n",
    "                   'FG3M_A', 'FG3A_A', 'FG3_PCT_A', 'FTM_A', 'FTA_A', 'FT_PCT_A', 'OREB_A',\n",
    "                   'DREB_A', 'REB_A', 'AST_A', 'STL_A', 'BLK_A', 'TOV_A', 'PF_A', 'PTS_A',\n",
    "                   'PLUS_MINUS_A']].to_numpy()\n",
    "                    team_it += 1\n",
    "\n",
    "                it1 -= 1    \n",
    "\n",
    "            if it2 < inter_stats_df.shape[0]:\n",
    "                if inter_stats_df.iloc[it2]['TEAM_NAME_H'] not in team_dict.keys():  \n",
    "                    team_dict[inter_stats_df.iloc[it2]['TEAM_NAME_H']] = ''\n",
    "\n",
    "                    pop_stats_arr[team_it] = inter_stats_df.iloc[it2][['FGM_H', 'FGA_H', 'FG_PCT_H', 'FG3M_H', 'FG3A_H', 'FG3_PCT_H', 'FTM_H',\n",
    "                   'FTA_H', 'FT_PCT_H', 'OREB_H', 'DREB_H', 'REB_H', 'AST_H', 'STL_H',\n",
    "                   'BLK_H', 'TOV_H', 'PF_H', 'PTS_H', 'PLUS_MINUS_H']].to_numpy()\n",
    "                    team_it += 1\n",
    "\n",
    "                if inter_stats_df.iloc[it2]['TEAM_NAME_A'] not in team_dict.keys():\n",
    "                    team_dict[inter_stats_df.iloc[it2]['TEAM_NAME_A']] = ''\n",
    "\n",
    "                    pop_stats_arr[team_it] = stats_df.iloc[it2][['FGM_A', 'FGA_A', 'FG_PCT_A',\n",
    "                   'FG3M_A', 'FG3A_A', 'FG3_PCT_A', 'FTM_A', 'FTA_A', 'FT_PCT_A', 'OREB_A',\n",
    "                   'DREB_A', 'REB_A', 'AST_A', 'STL_A', 'BLK_A', 'TOV_A', 'PF_A', 'PTS_A',\n",
    "                   'PLUS_MINUS_A']].to_numpy()\n",
    "                    team_it += 1\n",
    "\n",
    "                it2 += 1\n",
    "                \n",
    "        mean_stats = np.mean(pop_stats_arr, axis = 0)        \n",
    "        std_stats = np.std(pop_stats_arr, axis = 0)\n",
    "        \n",
    "        game_means[i] = mean_stats\n",
    "        game_stds[i] = std_stats\n",
    "        \n",
    "    return game_means, game_stds    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bdd2734a-e5b8-4033-bf74-bcea799bc057",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_and_standardize_sklearn(stats_df):\n",
    "    columns = ['FGM', 'FGA', 'FG_PCT', 'FG3M',\n",
    "           'FG3A', 'FG3_PCT', 'FTM', 'FTA', 'FT_PCT', 'OREB', 'DREB', 'REB', 'AST',\n",
    "           'STL', 'BLK', 'TOV', 'PF', 'PTS', 'PLUS_MINUS', 'E_OFF_RATING', 'OFF_RATING', 'E_DEF_RATING',\n",
    "           'DEF_RATING', 'E_NET_RATING', 'NET_RATING', 'AST_PCT', 'AST_TO',\n",
    "           'AST_RATIO', 'OREB_PCT', 'DREB_PCT', 'REB_PCT', 'TM_TOV_PCT', 'EFG_PCT',\n",
    "           'TS_PCT', 'E_PACE', 'PACE', 'PACE_PER40', 'POSS', 'PIE', 'GP_RANK',\n",
    "           'W_RANK', 'L_RANK', 'W_PCT_RANK', 'MIN_RANK', 'OFF_RATING_RANK',\n",
    "           'DEF_RATING_RANK', 'NET_RATING_RANK', 'AST_PCT_RANK', 'AST_TO_RANK',\n",
    "           'AST_RATIO_RANK', 'OREB_PCT_RANK', 'DREB_PCT_RANK', 'REB_PCT_RANK',\n",
    "           'TM_TOV_PCT_RANK', 'EFG_PCT_RANK', 'TS_PCT_RANK', 'PACE_RANK',\n",
    "           'PIE_RANK']\n",
    "    home_columns = [var + \"_H\" for var in columns]\n",
    "    away_columns = [var + \"_A\" for var in columns]\n",
    "    home_stats = np.empty((stats_df.shape[0], 51))\n",
    "    away_stats = np.empty((stats_df.shape[0], 51))\n",
    "    \n",
    "    home_stats = np.array(stats_df[home_columns])\n",
    "    away_stats = np.array(stats_df[away_columns])\n",
    "    ####\n",
    "    ##NEED TO FIX\n",
    "    w_l_dict = {\"W\" : 1, \"L\" : 0}\n",
    "    w_l_df = stats_df.replace({\"WL_H\": w_l_dict})\n",
    "    print(w_l_df.columns)\n",
    "    win_loss_home = np.array(w_l_df[\"WL_H\"])\n",
    "    matchups = stats_df[['TEAM_NAME_A', 'TEAM_NAME_H']]\n",
    "    \n",
    "    #standardize home and away stats \n",
    "    scaler = StandardScaler()\n",
    "    final = np.subtract(home_stats, away_stats)\n",
    "    final = scaler.fit_transform(final)\n",
    "    final = pd.DataFrame(final, columns = columns)\n",
    "   \n",
    "    return final, win_loss_home, matchups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8f6539c-4a6a-47ed-988d-2ebb9c453d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_full_train_test(num_years):\n",
    "    start_year = 2022 - num_years\n",
    "    all_years_stats_df = pd.DataFrame()\n",
    "    #For each year, \n",
    "    for i in range(start_year, 2022):\n",
    "        time.sleep(1)\n",
    "        games = leaguegamelog.LeagueGameLog(season = str(i))\n",
    "        df = pd.DataFrame(games.get_data_frames()[0])\n",
    "        df = df[df['WL'].notnull()]\n",
    "        teams = df['TEAM_NAME'].unique()\n",
    "        stats_df = generate_game_stats(df, teams, i)\n",
    "        \n",
    "        all_years_stats_df = pd.concat([all_years_stats_df, stats_df], axis = 0)\n",
    "        \n",
    "    attributes, target, matchups = normalize_and_standardize_sklearn(all_years_stats_df)\n",
    "    \n",
    "    train_X = attributes[:int(attributes.shape[0]*0.7)]\n",
    "    test_X = attributes[int(attributes.shape[0]*0.7):]\n",
    "    train_Y = target[:int(target.shape[0]*0.7)]\n",
    "    test_Y = target[int(target.shape[0]*0.7):]\n",
    "    \n",
    "    matchups_train = matchups[:int(matchups.shape[0]*0.7)]\n",
    "    matchups_test = matchups[int(matchups.shape[0]*0.7):]\n",
    "    \n",
    "    #return train_X, train_Y, test_X, test_Y\n",
    "    return train_X, np.ravel(train_Y), test_X, np.ravel(test_Y), matchups_train, matchups_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1db66b62-52e0-4187-ad1e-35831246b1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#From David Dale on stackoverflow\n",
    "def logit_pvalue(model, x):\n",
    "    \"\"\" Calculate z-scores for scikit-learn LogisticRegression.\n",
    "    parameters:\n",
    "        model: fitted sklearn.linear_model.LogisticRegression with intercept and large C\n",
    "        x:     matrix on which the model was fit\n",
    "    This function uses asymtptics for maximum likelihood estimates.\n",
    "    \"\"\"\n",
    "    p = model.predict_proba(x)\n",
    "    n = len(p)\n",
    "    m = len(model.coef_[0]) + 1\n",
    "    coefs = np.concatenate([model.intercept_, model.coef_[0]])\n",
    "    x_full = np.matrix(np.insert(np.array(x), 0, 1, axis = 1))\n",
    "    ans = np.zeros((m, m))\n",
    "    for i in range(n):\n",
    "        ans = ans + np.dot(np.transpose(x_full[i, :]), x_full[i, :]) * p[i,1] * p[i, 0]\n",
    "    vcov = np.linalg.inv(np.matrix(ans))\n",
    "    se = np.sqrt(np.diag(vcov))\n",
    "    t =  coefs/se  \n",
    "    p = (1 - norm.cdf(abs(t))) * 2\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd39c59c-0c52-4778-9792-2f1d0152f035",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get rid of multicolinear variables and keep significant ones\n",
    "def eliminate_attributes(train_X, test_X):\n",
    "    X = pd.DataFrame(train_X)\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"feature\"] = X.columns\n",
    "    vif_data[\"VIF\"] = [variance_inflation_factor(X.values, i)\n",
    "                              for i in range(len(X.columns))]\n",
    "    #print(vif_data)\n",
    "\n",
    "    feat_tokeep = list(vif_data[vif_data[\"VIF\"] < 5000][\"feature\"])\n",
    "    \n",
    "    #Modify training data to remove most multi colinear variables\n",
    "    train_X = train_X[feat_tokeep]\n",
    "    test_X = test_X[feat_tokeep]\n",
    "    \n",
    "    return train_X, test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6aa742fb-36c4-4284-9f20-33021cec18b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_odds(train_X, train_Y, test_X, matchups_test):\n",
    "    clf = LogisticRegression(random_state=0, C=0.1).fit(train_X, train_Y)\n",
    "    pred_prob = clf.predict_proba(test_X)\n",
    "    #pred_prob = pd.DataFrame(pred_prob, columns = [\"Away\", \"Home\"])    \n",
    "    #pred_winners = \n",
    "    return pd.DataFrame(pred_prob, columns = [\"Away\", \"Home\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db03a4bc-5055-47ef-a406-720e771e4ecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([34.142857142857146, 80.85714285714286, 0.42342857142857143, ...,\n",
       "       'San Antonio Spurs', 'SAS @ DAL', 'W'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2f53df1-d326-4d88-b48b-25479a827c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['FGM_H', 'FGA_H', 'FG_PCT_H', 'FG3M_H', 'FG3A_H', 'FG3_PCT_H', 'FTM_H',\n",
      "       'FTA_H', 'FT_PCT_H', 'OREB_H',\n",
      "       ...\n",
      "       'REB_PCT_RANK_A', 'TM_TOV_PCT_RANK_A', 'EFG_PCT_RANK_A',\n",
      "       'TS_PCT_RANK_A', 'PACE_RANK_A', 'PIE_RANK_A', 'GAME_DATE_A',\n",
      "       'TEAM_NAME_A', 'MATCHUP_A', 'WL_A'],\n",
      "      dtype='object', length=124)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\batar\\desktop\\nba\\env\\lib\\site-packages\\statsmodels\\stats\\outliers_influence.py:195: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  vif = 1. / (1. - r_squared_i)\n",
      "c:\\users\\batar\\desktop\\nba\\env\\lib\\site-packages\\statsmodels\\regression\\linear_model.py:1738: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return 1 - self.ssr/self.uncentered_tss\n"
     ]
    }
   ],
   "source": [
    "train_X, train_Y, test_X, test_Y, matchups_train, matchups_test = generate_full_train_test(10)\n",
    "train_X, test_X = eliminate_attributes(train_X, test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2bfc22-6b3b-495e-866a-e75648b5840a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_odds(train_X, train_Y, test_X, matchups_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b78095-6610-4781-a5e2-b08fffb7ff81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit model\n",
    "clf = LogisticRegression(random_state=0, C=0.1).fit(train_X, train_Y)\n",
    "y_pred = clf.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390e906a-2d50-4bed-8de8-07a0fac99e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train accuracy\n",
    "clf.score(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf6dee0-10de-4506-aabf-fe4ec689317a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test accuracy\n",
    "accuracy_score(test_Y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273a73db-c3a4-41f4-b176-7ca57ce3c087",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grid Search\n",
    "lr = LogisticRegression()\n",
    "grid_values = {'penalty': ['l1','l2'], 'C': [0.001,0.01,0.1,1,10,100,1000], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'], 'max_iter': [20, 50, 100, 200, 500, 1000]}\n",
    "clf = GridSearchCV(lr, param_grid=grid_values)\n",
    "clf.fit(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f91f1a7-11aa-4920-9fae-b3912744ee8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe0b36d-3cdd-48c9-a5cd-543b2276f6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test\n",
    "games = leaguegamelog.LeagueGameLog(season = '2021')\n",
    "games_df = pd.DataFrame(games.get_data_frames()[0])\n",
    "#teams = df['TEAM_NAME'].unique()\n",
    "#stats_df = generate_game_stats(df, teams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635af645-bccc-490b-8262-6078709ae6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBoost Test\n",
    "xgb_cl = xgb.XGBClassifier()\n",
    "# Fit\n",
    "xgb_cl.fit(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f6730f-c595-4a58-9b80-6b4616d191ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "y_pred = xgb_cl.predict(test_X)\n",
    "accuracy_score(test_Y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddaeda2-32ee-4c32-b582-9de9c6b8e7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "games = leaguegamelog.LeagueGameLog(season = '2018')\n",
    "df = pd.DataFrame(games.get_data_frames()[0])\n",
    "\n",
    "\n",
    "\n",
    "team_df = df[df['TEAM_NAME'] == 'San Antonio Spurs']\n",
    "advanced_stats = get_advanced_stats(2018)\n",
    "temp_df = team_df.merge(advanced_stats, on = [\"GAME_ID\", \"TEAM_ID\"], suffixes = (\"\", \"_y\"))\n",
    "to_drop = [x for x in temp_df if x.endswith('_y')]\n",
    "temp_df.drop(to_drop, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882edbaa-6a68-44ef-a868-c6a8abc2a0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Things to do\n",
    "# Add playoff data\n",
    "# Add ELO Rating\n",
    "# Add player-based statistics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
