{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71dbaa1c-5eab-4319-9bb6-be4a737e6b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\batar\\desktop\\nba\\env\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "from nba_api.stats.endpoints import leaguegamelog\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a073fba3-76e4-4b96-a4d2-ba591a8ffb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Can use this to get means and standard deviations\n",
    "def generate_game_stats(df, teams): \n",
    "    #all_stats_arr = np.empty((30, 77, 19))\n",
    "    all_teams_stats_df = pd.DataFrame()\n",
    "    for i, team in enumerate(teams):\n",
    "        temp_df = df[df['TEAM_NAME'] == team]\n",
    "        temp_df = temp_df.sort_values(by = ['GAME_DATE'])\n",
    "        temp_df = temp_df.set_index('GAME_ID')\n",
    "        key_data = temp_df[['GAME_DATE', 'TEAM_NAME', 'MATCHUP', 'WL']].iloc[5:]\n",
    "        temp_df = temp_df[[\n",
    "           'FGM', 'FGA', 'FG_PCT', 'FG3M',\n",
    "           'FG3A', 'FG3_PCT', 'FTM', 'FTA', 'FT_PCT', 'OREB', 'DREB', 'REB', 'AST',\n",
    "           'STL', 'BLK', 'TOV', 'PF', 'PTS', 'PLUS_MINUS']]\n",
    "        #final_stats_df = temp_df.rolling(5).mean().shift(periods = 1).iloc[5:]#.to_dict('list')\n",
    "        #single_stats_arr = final_stats_df.to_numpy()\n",
    "        #all_stats_arr[i] = single_stats_arr\n",
    "        \n",
    "        final_organized_stats = temp_df.rolling(5).mean().shift(periods = 1).iloc[5:]#.to_dict('index')\n",
    "        stats_with_key = pd.concat([final_organized_stats, key_data], axis = 1)\n",
    "     \n",
    "        all_teams_stats_df = pd.concat([all_teams_stats_df, stats_with_key], axis = 0)\n",
    "        \n",
    "    home_df = all_teams_stats_df[all_teams_stats_df['MATCHUP'].str.contains(\"vs.\")]\n",
    "    away_df = all_teams_stats_df[all_teams_stats_df['MATCHUP'].str.contains(\"@\")]\n",
    "    merged_game_stats_df = home_df.merge(away_df, on = \"GAME_ID\",suffixes = (\"_H\", \"_A\"))\n",
    "    merged_game_stats_df = merged_game_stats_df.sort_values(by = ['GAME_DATE_H'])\n",
    "      \n",
    "    return merged_game_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4720cefa-b177-4efc-99df-3fce22dea1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to get population mean and standard deviations - might be stupid but I think it makes sense\n",
    "#Make sure to use this on train and test set separately \n",
    "#After this, make these stats for each game their own matrices, so I could do (game_matrix - mean_matrix / std_matrix)\n",
    "def generate_population_statistics(stats_df):\n",
    "    game_means = np.empty((stats_df.shape[0], 19))\n",
    "    game_stds = np.empty((stats_df.shape[0], 19))\n",
    "    \n",
    "    for i in range(stats_df.shape[0]):\n",
    "        inter_stats_df = stats_df[stats_df['GAME_DATE_H'].str.contains(stats_df.iloc[i]['GAME_DATE_H'][0:4])]\n",
    "        inter_index = stats_df.index[i]\n",
    "        it1 = np.where(inter_stats_df.index == inter_index)[0][0]\n",
    "        team_dict = {}\n",
    "        pop_stats_arr = np.empty((30, 19))\n",
    "        it2 = it1+1\n",
    "        team_it = 0\n",
    "    \n",
    "        while len(team_dict.keys()) < 30:\n",
    "\n",
    "            if it1 >= 0:\n",
    "\n",
    "                if inter_stats_df.iloc[it1]['TEAM_NAME_H'] not in team_dict.keys():  \n",
    "                    team_dict[inter_stats_df.iloc[it1]['TEAM_NAME_H']] = ''\n",
    "\n",
    "                    pop_stats_arr[team_it] = inter_stats_df.iloc[it1][['FGM_H', 'FGA_H', 'FG_PCT_H', 'FG3M_H', 'FG3A_H', 'FG3_PCT_H', 'FTM_H',\n",
    "                   'FTA_H', 'FT_PCT_H', 'OREB_H', 'DREB_H', 'REB_H', 'AST_H', 'STL_H',\n",
    "                   'BLK_H', 'TOV_H', 'PF_H', 'PTS_H', 'PLUS_MINUS_H']].to_numpy()\n",
    "                    team_it += 1\n",
    "\n",
    "                if inter_stats_df.iloc[it1]['TEAM_NAME_A'] not in team_dict.keys():\n",
    "                    team_dict[inter_stats_df.iloc[it1]['TEAM_NAME_A']] = ''\n",
    "\n",
    "                    pop_stats_arr[team_it] = inter_stats_df.iloc[it1][['FGM_A', 'FGA_A', 'FG_PCT_A',\n",
    "                   'FG3M_A', 'FG3A_A', 'FG3_PCT_A', 'FTM_A', 'FTA_A', 'FT_PCT_A', 'OREB_A',\n",
    "                   'DREB_A', 'REB_A', 'AST_A', 'STL_A', 'BLK_A', 'TOV_A', 'PF_A', 'PTS_A',\n",
    "                   'PLUS_MINUS_A']].to_numpy()\n",
    "                    team_it += 1\n",
    "\n",
    "                it1 -= 1    \n",
    "\n",
    "            if it2 < inter_stats_df.shape[0]:\n",
    "                if inter_stats_df.iloc[it2]['TEAM_NAME_H'] not in team_dict.keys():  \n",
    "                    team_dict[inter_stats_df.iloc[it2]['TEAM_NAME_H']] = ''\n",
    "\n",
    "                    pop_stats_arr[team_it] = inter_stats_df.iloc[it2][['FGM_H', 'FGA_H', 'FG_PCT_H', 'FG3M_H', 'FG3A_H', 'FG3_PCT_H', 'FTM_H',\n",
    "                   'FTA_H', 'FT_PCT_H', 'OREB_H', 'DREB_H', 'REB_H', 'AST_H', 'STL_H',\n",
    "                   'BLK_H', 'TOV_H', 'PF_H', 'PTS_H', 'PLUS_MINUS_H']].to_numpy()\n",
    "                    team_it += 1\n",
    "\n",
    "                if inter_stats_df.iloc[it2]['TEAM_NAME_A'] not in team_dict.keys():\n",
    "                    team_dict[inter_stats_df.iloc[it2]['TEAM_NAME_A']] = ''\n",
    "\n",
    "                    pop_stats_arr[team_it] = stats_df.iloc[it2][['FGM_A', 'FGA_A', 'FG_PCT_A',\n",
    "                   'FG3M_A', 'FG3A_A', 'FG3_PCT_A', 'FTM_A', 'FTA_A', 'FT_PCT_A', 'OREB_A',\n",
    "                   'DREB_A', 'REB_A', 'AST_A', 'STL_A', 'BLK_A', 'TOV_A', 'PF_A', 'PTS_A',\n",
    "                   'PLUS_MINUS_A']].to_numpy()\n",
    "                    team_it += 1\n",
    "\n",
    "                it2 += 1\n",
    "                \n",
    "        mean_stats = np.mean(pop_stats_arr, axis = 0)        \n",
    "        std_stats = np.std(pop_stats_arr, axis = 0)\n",
    "        \n",
    "        game_means[i] = mean_stats\n",
    "        game_stds[i] = std_stats\n",
    "        \n",
    "    return game_means, game_stds    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7b22bca0-dd60-402f-be37-ef26abc1412b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to get z scores and finalize attributes as (Home minus Away)\n",
    "def normalize_and_standardize(stats_df, game_means, game_stds):\n",
    "   \n",
    "    home_stats = np.empty((stats_df.shape[0], 19))\n",
    "    away_stats = np.empty((stats_df.shape[0], 19))\n",
    "    \n",
    "    home_stats = stats_df.iloc[:, 0:19]\n",
    "    away_stats = stats_df.iloc[:, 23:42]\n",
    "    win_loss_home = stats_df.iloc[:, 22]\n",
    "    matchup = stats_df.iloc[:, [43, 20]]\n",
    "    \n",
    "    #standardize home and away stats \n",
    "    home_z = np.divide((home_stats - game_means), game_stds)\n",
    "    \n",
    "    away_z = np.divide((away_stats - game_means), game_stds)\n",
    "    \n",
    "    final = np.subtract(home_z, away_z)\n",
    "    \n",
    "    final = pd.DataFrame(final)\n",
    "\n",
    "    final = pd.concat([final, win_loss_home], axis = 1)\n",
    "    \n",
    "    return final, matchup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdd2734a-e5b8-4033-bf74-bcea799bc057",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_and_standardize_sklearn(stats_df):\n",
    "    \n",
    "    home_stats = np.empty((stats_df.shape[0], 19))\n",
    "    away_stats = np.empty((stats_df.shape[0], 19))\n",
    "    \n",
    "    home_stats = stats_df.iloc[:, 0:19]\n",
    "    away_stats = stats_df.iloc[:, 23:42]\n",
    "    win_loss_home = stats_df.iloc[:, 22]\n",
    "    matchup = stats_df.iloc[:, [43, 20]]\n",
    "    \n",
    "    #standardize home and away stats \n",
    "    scaler = StandardScaler()\n",
    "    home_z = scaler.fit_transform(home_stats)\n",
    "    \n",
    "    away_z = scaler.fit_transform(away_stats)\n",
    "    \n",
    "    final = np.subtract(home_z, away_z)\n",
    "    \n",
    "    final = pd.DataFrame(final)\n",
    "\n",
    "    #final = pd.concat([final, win_loss_home], axis = 1)\n",
    "    \n",
    "    return final, win_loss_home, matchup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27533d1e-464d-4eae-87b1-1cdb34ebf2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Include num_years previous years plus current season games\n",
    "def generate_full_train_test(num_years):\n",
    "    start_year = 2022 - num_years\n",
    "    all_years_stats_df = pd.DataFrame()\n",
    "    #For each year, \n",
    "    for i in range(start_year, 2022):\n",
    "        time.sleep(1)\n",
    "        games = leaguegamelog.LeagueGameLog(season = str(i))\n",
    "        df = pd.DataFrame(games.get_data_frames()[0])\n",
    "        teams = df['TEAM_NAME'].unique()\n",
    "        stats_df = generate_game_stats(df, teams)\n",
    "        \n",
    "        all_years_stats_df = pd.concat([all_years_stats_df, stats_df], axis = 0)\n",
    "        \n",
    "    \n",
    "    #Split data into train and test and transform\n",
    "    train_stats = all_years_stats_df.iloc[:int(all_years_stats_df.shape[0]*0.7), :]\n",
    "    test_stats = all_years_stats_df.iloc[int(all_years_stats_df.shape[0]*0.7):, :]\n",
    "\n",
    "    game_means_train, game_stds_train = generate_population_statistics(train_stats)\n",
    "    game_means_test, game_stds_test = generate_population_statistics(test_stats)\n",
    "    \n",
    "    #Finalize and prepare train / test\n",
    "    final_train, matchup_train = normalize_and_standardize(train_stats, game_means_train, game_stds_train)\n",
    "    final_test, matchup_test = normalize_and_standardize(test_stats, game_means_test, game_stds_test)\n",
    "    \n",
    "    #Prepare actual train and test\n",
    "    train_X = final_train.iloc[:,:19]\n",
    "    train_Y = final_train.iloc[:,19]\n",
    "\n",
    "    test_X = final_test.iloc[:, :19]\n",
    "    test_Y = final_test.iloc[:,19]\n",
    "    \n",
    "    return train_X, train_Y, test_X, test_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8f6539c-4a6a-47ed-988d-2ebb9c453d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_full_train_test_sklearn(num_years):\n",
    "    start_year = 2022 - num_years\n",
    "    all_years_stats_df = pd.DataFrame()\n",
    "    #For each year, \n",
    "    for i in range(start_year, 2022):\n",
    "        time.sleep(1)\n",
    "        games = leaguegamelog.LeagueGameLog(season = str(i))\n",
    "        df = pd.DataFrame(games.get_data_frames()[0])\n",
    "        teams = df['TEAM_NAME'].unique()\n",
    "        stats_df = generate_game_stats(df, teams)\n",
    "        \n",
    "        all_years_stats_df = pd.concat([all_years_stats_df, stats_df], axis = 0)\n",
    "        \n",
    "    \n",
    "    #Split data into train and test and transform\n",
    "    train_stats = all_years_stats_df.iloc[:int(all_years_stats_df.shape[0]*0.7), :]\n",
    "    test_stats = all_years_stats_df.iloc[int(all_years_stats_df.shape[0]*0.7):, :]\n",
    "\n",
    "    #Finalize and prepare train / test\n",
    "    train_X, train_Y, matchup_train = normalize_and_standardize_sklearn(train_stats)\n",
    "    test_X, test_Y, matchup_test = normalize_and_standardize_sklearn(test_stats)\n",
    "    \n",
    "    return train_X, train_Y, test_X, test_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab3353c9-84ea-4cad-bf57-704cfd0ef3a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\batar\\AppData\\Local\\Temp\\ipykernel_14000\\1595565284.py:17: FutureWarning: Calling a ufunc on non-aligned DataFrames (or DataFrame/Series combination). Currently, the indices are ignored and the result takes the index/columns of the first DataFrame. In the future , the DataFrames/Series will be aligned before applying the ufunc.\n",
      "Convert one of the arguments to a NumPy array (eg 'ufunc(df1, np.asarray(df2)') to keep the current behaviour, or align manually (eg 'df1, df2 = df1.align(df2)') before passing to the ufunc to obtain the future behaviour and silence this warning.\n",
      "  final = np.subtract(home_z, away_z)\n",
      "C:\\Users\\batar\\AppData\\Local\\Temp\\ipykernel_14000\\1595565284.py:17: FutureWarning: Calling a ufunc on non-aligned DataFrames (or DataFrame/Series combination). Currently, the indices are ignored and the result takes the index/columns of the first DataFrame. In the future , the DataFrames/Series will be aligned before applying the ufunc.\n",
      "Convert one of the arguments to a NumPy array (eg 'ufunc(df1, np.asarray(df2)') to keep the current behaviour, or align manually (eg 'df1, df2 = df1.align(df2)') before passing to the ufunc to obtain the future behaviour and silence this warning.\n",
      "  final = np.subtract(home_z, away_z)\n"
     ]
    }
   ],
   "source": [
    "train_X, train_Y, test_X, test_Y = generate_full_train_test(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f53df1-d326-4d88-b48b-25479a827c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_Y, test_X, test_Y = generate_full_train_test_sklearn(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe0b36d-3cdd-48c9-a5cd-543b2276f6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test\n",
    "games = leaguegamelog.LeagueGameLog(season = '2018')\n",
    "df = pd.DataFrame(games.get_data_frames()[0])\n",
    "teams = df['TEAM_NAME'].unique()\n",
    "stats_df = generate_game_stats(df, teams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71da959d-8b94-4b57-b4c8-60620387ea7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "away_z = normalize_and_standardize_sklearn(stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1b78095-6610-4781-a5e2-b08fffb7ff81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit model\n",
    "clf = LogisticRegression(random_state=420).fit(train_X, train_Y)\n",
    "y_pred = clf.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "390e906a-2d50-4bed-8de8-07a0fac99e9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.630801687763713"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train accuracy\n",
    "clf.score(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bcf6dee0-10de-4506-aabf-fe4ec689317a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'NoneType' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Test accuracy\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43maccuracy_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_Y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\users\\batar\\desktop\\nba\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:211\u001b[0m, in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;124;03m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[0;32m    146\u001b[0m \n\u001b[0;32m    147\u001b[0m \u001b[38;5;124;03mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;124;03m0.5\u001b[39;00m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    210\u001b[0m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[1;32m--> 211\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    212\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\users\\batar\\desktop\\nba\\env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:85\u001b[0m, in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \n\u001b[0;32m     60\u001b[0m \u001b[38;5;124;03mThis converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[38;5;124;03my_pred : array or indicator matrix\u001b[39;00m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     84\u001b[0m check_consistent_length(y_true, y_pred)\n\u001b[1;32m---> 85\u001b[0m type_true \u001b[38;5;241m=\u001b[39m \u001b[43mtype_of_target\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     86\u001b[0m type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred)\n\u001b[0;32m     88\u001b[0m y_type \u001b[38;5;241m=\u001b[39m {type_true, type_pred}\n",
      "File \u001b[1;32mc:\\users\\batar\\desktop\\nba\\env\\lib\\site-packages\\sklearn\\utils\\multiclass.py:327\u001b[0m, in \u001b[0;36mtype_of_target\u001b[1;34m(y)\u001b[0m\n\u001b[0;32m    324\u001b[0m     _assert_all_finite(y)\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontinuous\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m suffix\n\u001b[1;32m--> 327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mlen\u001b[39m(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (y\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(y[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m    328\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m suffix  \u001b[38;5;66;03m# [1, 2, 3] or [[1., 2., 3]] or [[1, 2]]\u001b[39;00m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36munique\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\users\\batar\\desktop\\nba\\env\\lib\\site-packages\\numpy\\lib\\arraysetops.py:272\u001b[0m, in \u001b[0;36munique\u001b[1;34m(ar, return_index, return_inverse, return_counts, axis)\u001b[0m\n\u001b[0;32m    270\u001b[0m ar \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(ar)\n\u001b[0;32m    271\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 272\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43m_unique1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_inverse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_counts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    273\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _unpack_tuple(ret)\n\u001b[0;32m    275\u001b[0m \u001b[38;5;66;03m# axis was specified and not None\u001b[39;00m\n",
      "File \u001b[1;32mc:\\users\\batar\\desktop\\nba\\env\\lib\\site-packages\\numpy\\lib\\arraysetops.py:333\u001b[0m, in \u001b[0;36m_unique1d\u001b[1;34m(ar, return_index, return_inverse, return_counts)\u001b[0m\n\u001b[0;32m    331\u001b[0m     aux \u001b[38;5;241m=\u001b[39m ar[perm]\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 333\u001b[0m     \u001b[43mar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    334\u001b[0m     aux \u001b[38;5;241m=\u001b[39m ar\n\u001b[0;32m    335\u001b[0m mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(aux\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mbool_)\n",
      "\u001b[1;31mTypeError\u001b[0m: '<' not supported between instances of 'NoneType' and 'str'"
     ]
    }
   ],
   "source": [
    "#Test accuracy\n",
    "accuracy_score(test_Y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1898aba4-b6a2-4dec-81d6-042eef5ca68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7201b534-6713-493b-b2b3-575c37c2a335",
   "metadata": {},
   "outputs": [],
   "source": [
    "dumby_check = np.repeat('W', 1626)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df1500d-57f0-4ba6-9eed-3339d79e4343",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Winners edge is ~ 5%\n",
    "accuracy_score(test_Y, dumby_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332fdc69-25bc-4683-900c-dbf520335bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635af645-bccc-490b-8262-6078709ae6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#XGBoost Test\n",
    "xgb_cl = xgb.XGBClassifier()\n",
    "# Fit\n",
    "xgb_cl.fit(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f6730f-c595-4a58-9b80-6b4616d191ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict\n",
    "y_pred = xgb_cl.predict(test_X)\n",
    "accuracy_score(test_Y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c83cee-a186-4e13-9253-ec61bd65dcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pull and store data\n",
    "#Modify this to concat yearly statistics for larger training set\n",
    "games = leaguegamelog.LeagueGameLog(season = '2018')\n",
    "df = pd.DataFrame(games.get_data_frames()[0])\n",
    "teams = df['TEAM_NAME'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea10d240-3799-4289-a8e5-4421d9c17083",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get rolling averages and join like games into (home, away)\n",
    "stats_df = generate_game_stats(df, teams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5199269b-cd79-4676-b74b-ed6b50862c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(stats_df.index == '0021801228')[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a0ede4-53c6-4380-af89-3e8371fb8c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df['GAME_DATE_H'].str.contains(stats_df.iloc[2]['GAME_DATE_H'][0:4]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc8decb-75cd-4107-88a6-194ed27c0bf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d97f892-0420-4624-aa2e-eb91d0201e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data into train and test and transform\n",
    "train_stats = stats_df.iloc[:int(stats_df.shape[0]*0.7), :]\n",
    "test_stats = stats_df.iloc[int(stats_df.shape[0]*0.7):, :]\n",
    "\n",
    "game_means_train, game_stds_train = generate_population_statistics(train_stats)\n",
    "game_means_test, game_stds_test = generate_population_statistics(test_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc216f51-bc74-4046-b50a-71f6b4960044",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finalize and prepare train / test\n",
    "final_train, matchup_train = normalize_and_standardize(train_stats, game_means_train, game_stds_train)\n",
    "final_test, matchup_test = normalize_and_standardize(test_stats, game_means_test, game_stds_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0f3ee9-ae3e-499f-8ee6-8d547460938a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare actual train and test\n",
    "train_X = final_train.iloc[:,:19]\n",
    "train_Y = final_train.iloc[:,19]\n",
    "\n",
    "test_X = final_test.iloc[:, :19]\n",
    "test_Y = final_test.iloc[:,19]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7ca478-cb0a-44b1-8a28-9f97e829bd17",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdc2463-e383-4e59-aeb7-a8a725b4bf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit model\n",
    "clf = LogisticRegression(random_state=420).fit(train_X, train_Y)\n",
    "y_pred = clf.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce15ff98-5bd5-4055-9976-60cce13fc5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train accuracy\n",
    "clf.score(train_X, train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d4427f-950b-4286-8a42-28ecd5511420",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test accuracy\n",
    "accuracy_score(test_Y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c207436-402e-4aec-b510-da95fd102efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.predict([[-3,-3,-3,-3,-3,-3,-3,-3,-3,-3,-3,-3,-3,-3,-3,-3,-3,-3,-3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58cb27c-06f9-47e7-84f5-ced85f6217a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc2b94e-64ad-420b-a551-28f083b0ef16",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Next steps\n",
    "#See if more data helps\n",
    "#See if more attributes help (advanced stats)\n",
    "#See if different rolling averages have different performance\n",
    "#Try ML (XGBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558ad084-87ab-46ed-8d32-17ff3babd9cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157832dd-8761-41ed-af40-2d36974f4701",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df.iloc[:, [20,43]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55384965-a5db-45d8-9618-1d98fda994ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950da2f6-ccf9-420c-a6cf-f17df998b148",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_means, game_stds = generate_population_statistics(stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2bbee7-0f85-4f10-a6a7-e89a19eabed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5228ed32-4479-49e7-903b-eeb33d7a8452",
   "metadata": {},
   "outputs": [],
   "source": [
    "final, matchup = normalize_and_standardize(stats_df, game_means, game_stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd04669-e1ff-4660-94e1-f3afec8696d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "matchup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e9e94b-8be5-4ceb-b540-bc8ab54aeb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare training and test data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bef1b17-44ae-47ab-b008-2933fe069a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f96e50c-7322-4797-8bdc-9362d9cf9d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to flatten stats dict and find averages. Would show average and std dev. of team atttributes for 5th, \n",
    "# 6th... 82nd game\n",
    "\n",
    "num_teams = teams.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb4171e-5728-4abc-bcb4-e580e32f0781",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "team = 'Oklahoma City Thunder'\n",
    "temp_df = df[df['TEAM_NAME'] == team]\n",
    "temp_df = temp_df.sort_values(by = ['GAME_DATE'])\n",
    "temp_df = temp_df.set_index('GAME_ID')\n",
    "temp_df = temp_df[[\n",
    "           'FGM', 'FGA', 'FG_PCT', 'FG3M',\n",
    "           'FG3A', 'FG3_PCT', 'FTM', 'FTA', 'FT_PCT', 'OREB', 'DREB', 'REB', 'AST',\n",
    "           'STL', 'BLK', 'TOV', 'PF', 'PTS', 'PLUS_MINUS']]\n",
    "final_stats_df = temp_df.rolling(5).mean().shift(periods = 1).iloc[5:]\n",
    "single_stats_arr = final_stats_df.to_numpy()\n",
    "all_stats_arr = np.empty((30, 77, 19))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50021687-52ea-491a-95f2-5f24324663b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_calc_dict = {}\n",
    "descriptive_dict = {}\n",
    "all_stats_arr = np.empty((30, 77, 19))\n",
    "team = 'Oklahoma City Thunder'\n",
    "temp_df = df[df['TEAM_NAME'] == team]\n",
    "temp_df = temp_df.sort_values(by = ['GAME_DATE'])\n",
    "temp_df = temp_df.set_index('GAME_ID')\n",
    "key_data = temp_df[['TEAM_NAME', 'MATCHUP', 'WL']].iloc[5:]\n",
    "temp_df = temp_df[[\n",
    "           'FGM', 'FGA', 'FG_PCT', 'FG3M',\n",
    "           'FG3A', 'FG3_PCT', 'FTM', 'FTA', 'FT_PCT', 'OREB', 'DREB', 'REB', 'AST',\n",
    "           'STL', 'BLK', 'TOV', 'PF', 'PTS', 'PLUS_MINUS']]\n",
    "final_stats_df = temp_df.rolling(5).mean().shift(periods = 1).iloc[5:]\n",
    "single_stats_arr = final_stats_df.to_numpy()\n",
    "all_stats_arr[0] = single_stats_arr\n",
    "        \n",
    "final_organized_stats = temp_df.rolling(5).mean().shift(periods = 1).iloc[5:]\n",
    "stats_with_key = pd.concat([final_organized_stats, key_data], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d17829-ca60-41ef-94b6-b092a7639e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_teams_stats_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179a3b86-10e5-467b-aefa-324340e707ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_teams_stats_df = pd.concat([all_teams_stats_df, stats_with_key], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4886f462-8d3c-4de2-a240-ff19e50504de",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = df[df['TEAM_NAME'] == team]\n",
    "temp_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34f06e4-ecdc-4b5a-bade-d01e90c374e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_with_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f803cf5-27b7-4c99-b4df-59f601d3b833",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_organized_stats = temp_df.rolling(5).mean().shift(periods = 1).iloc[5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f933a1-8441-4dcb-9ae6-1954dbd4d78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_organized_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8530dc-343f-4ce2-8bd9-46c90fbde150",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_stats_df.to_numpy().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5504ce-f116-45a4-9857-cd771a697bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.from_dict(dict2['Oklahoma City Thunder'], orient = 'index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952f2259-d39d-4835-b788-28bfa6f386df",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict1, dict2 = generate_team_stats(df, teams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c22d45-8c41-44a9-b555-da82cfa384ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ae71ce-ed43-4c76-ba65-8a4df26f9f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = df[df['TEAM_NAME'] == 'Oklahoma City Thunder']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ad6840-0ef0-48ac-ae2e-9ced9fae9fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = temp_df.set_index('GAME_ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22442475-837a-4100-b49e-5d3263ac9c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_ids = temp_df['GAME_ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2a06c4-539a-45df-bc07-0e2a0504b5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = temp_df[[\n",
    "           'FGM', 'FGA', 'FG_PCT', 'FG3M',\n",
    "           'FG3A', 'FG3_PCT', 'FTM', 'FTA', 'FT_PCT', 'OREB', 'DREB', 'REB', 'AST',\n",
    "           'STL', 'BLK', 'TOV', 'PF', 'PTS', 'PLUS_MINUS']]\n",
    "temp_df.rolling(5).mean().shift(periods = 1).iloc[5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba690742-b562-4278-b81d-00da7338d44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_ids.shift(periods = 5).iloc[5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940568e2-699a-46c9-91d4-f973ddef215a",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = temp_df.sort_values(by = ['GAME_DATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee17df63-0735-44af-adfa-74e029d4b6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = temp_df[[\n",
    "       'FGM', 'FGA', 'FG_PCT', 'FG3M',\n",
    "       'FG3A', 'FG3_PCT', 'FTM', 'FTA', 'FT_PCT', 'OREB', 'DREB', 'REB', 'AST',\n",
    "       'STL', 'BLK', 'TOV', 'PF', 'PTS', 'PLUS_MINUS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248c9029-113c-4968-bb0b-3723e95e1d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df.rolling(5).mean().shift(periods = 1).tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040769d4-f77d-4d6a-ae32-b209b47b26d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e463bd-2f7a-4953-a1f6-9a4f075fd285",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data frames into home and away teams\n",
    "home_df = df[df['MATCHUP'].str.contains(\"vs.\")]\n",
    "away_df = df[df['MATCHUP'].str.contains(\"@\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95b216a-b60a-45f3-b11a-95e4b9e772ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = home_df.merge(away_df, on = \"GAME_ID\",suffixes = (\"_H\", \"_A\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c724d213-ba88-4b94-aa75-cb2bca504042",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b663d2-0214-4345-9c23-36721e32971c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make list of all team names, for loop filter by team n times, and make the rolling dict values?\n",
    "# Can then go in and replace values/make new df with the normalized vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3dcbe7-0b98-48ca-b4dc-2b4215919b4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
